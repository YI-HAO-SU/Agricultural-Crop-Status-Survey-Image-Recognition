{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db67b429",
   "metadata": {},
   "source": [
    "## Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc84052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "from datetime import date\n",
    "import glob\n",
    "from PIL import Image\n",
    "from torchvision import  transforms,datasets, models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd60e42",
   "metadata": {},
   "source": [
    "## Private variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42315a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_WEIGHTS = \"/work/u2785625/AI_Cup_2022/Weights\"\n",
    "PUBLIC_TESTING_PATH = \"/work/u2785625/AI_Cup_2022/ProcessedPublicTesting/\"\n",
    "folderNames = ['0','1','2','3','4','5','6','7','8','9','a','b','c','d','e','f']\n",
    "OUTPUT_CSV_PATH = \"/work/u2785625/AI_Cup_2022/PublicTesting_OutputCsv/\"\n",
    "\n",
    "local_dir = \"/work/u2785625/AI_Cup_2022/Datasets\"\n",
    "n_classes = 33\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f588974",
   "metadata": {},
   "source": [
    "## Testing Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f78f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfm = transforms.Compose([ #valid and grading\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((456,456)),\n",
    "    transforms.CenterCrop(456),\n",
    "    transforms.Normalize([.5, 0.5, 0.5], [0.5, 0.5, 0.5]), \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964bc008",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dd3112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.efficientnet_b5(weights='DEFAULT').to(device)\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.fc = nn.Linear(num_ftrs, n_classes)\n",
    "model.load_state_dict(torch.load(PATH_WEIGHTS))\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "data = datasets.ImageFolder(root = local_dir, transform = test_tfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a5251",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5102b014",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "List_FileName = list()\n",
    "List_Output = list()ＦＦ\n",
    "for folder in folderNames:\n",
    "    folderPath = PUBLIC_TESTING_PATH + folder + '/'\n",
    "    for fileName in glob.glob(folderPath + '*'):\n",
    "        img = Image.open(fileName)\n",
    "        x = test_tfm(img)\n",
    "        x = x.unsqueeze(0)\n",
    "        output = model(x)\n",
    "        _, pred = torch.max(output, dim = 1)\n",
    "        List_FileName.append(fileName[len(folderPath)::])\n",
    "        List_Output.append(data.classes[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61c6f378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       filename           label\n",
      "0      09462dbc-ecc4-45d7-8653-9e3a22bbacc2.jpg          longan\n",
      "1      059b89e1-80c1-43a4-be36-cc911dc440f9.jpg      greenhouse\n",
      "2      0ea762fd-124b-4db5-827a-60799a869870.jpg  chinesecabbage\n",
      "3      0e03f42d-70b7-4671-aefe-3e7402ac90a9.jpg     cauliflower\n",
      "4      0f8b5ffa-8609-4e05-afc0-56717bc0c113.jpg    bambooshoots\n",
      "...                                         ...             ...\n",
      "11143  f06bbcf8-f784-4810-92b9-c249c93f3f81.jpg            kale\n",
      "11144  f2efc7a7-48a6-429a-be7f-86884826f223.jpg    bambooshoots\n",
      "11145  fab7c542-6cc0-410c-8b33-8a9e0675029a.jpg      greenhouse\n",
      "11146  fe0231e7-fdf1-4415-b586-e0e815b39ba4.jpg            kale\n",
      "11147  fdc8142c-74ea-4cfe-baf8-bd9c70ed0da7.jpg     sweetpotato\n",
      "\n",
      "[11148 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "output_dict = {\"filename\": List_FileName,\n",
    "                \"label\": List_Output}\n",
    "Out_dataframe = pd.DataFrame(output_dict)\n",
    "print(Out_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3ca204",
   "metadata": {},
   "source": [
    "## Save Csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b6e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FileName =  date.today().strftime(\"%m/%d\").replace('/','') + '.csv'\n",
    "\n",
    "Out_dataframe.to_csv(OUTPUT_CSV_PATH + FileName , index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
