{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db67b429",
   "metadata": {},
   "source": [
    "## Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc84052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from datetime import date\n",
    "import glob\n",
    "from PIL import Image\n",
    "from torchvision import  transforms,datasets, models\n",
    "import torch.nn as nn\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd60e42",
   "metadata": {},
   "source": [
    "## Private variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42315a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_WEIGHTS = \"D:/ML_exercise/Weights\"\n",
    "#PUBLIC_TESTING_PATH = \"/work/u2785625/AI_Cup_2022/ProcessedPublicTesting/\"\n",
    "folderNames = ['0','1','2','3','4','5','6','7','8','9','a','b','c','d','e','f']\n",
    "OUTPUT_CSV_PATH = \"D:/ML_exercise/PublicTesting_OutputCsv\"\n",
    "\n",
    "#local_dir = \"/work/u2785625/AI_Cup_2022/Datasets\"\n",
    "local_dir = \"D:/ML_exercise\"\n",
    "n_classes = 33\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "species = ['asparagus', 'bambooshoots', 'betel', 'broccoli', 'cauliflower', 'chinesecabbage', 'chinesechives', 'custardapple', 'grape', 'greenhouse', 'greenonion', 'kale', 'lemon', 'lettuce', 'litchi', 'longan', 'loofah', 'mango', 'onion', 'others', 'papaya', 'passionfruit', 'pear', 'pennisetum', 'redbeans', 'roseapple', 'sesbania', 'soybeans', 'sunhemp', 'sweetpotato', 'taro', 'tea', 'waterbamboo']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f588974",
   "metadata": {},
   "source": [
    "## Testing Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f78f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfm = transforms.Compose([ #valid and grading\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((456,456)),\n",
    "    transforms.CenterCrop(456),\n",
    "    transforms.Normalize([.5, 0.5, 0.5], [0.5, 0.5, 0.5]), \n",
    "])\n",
    "\n",
    "#data = datasets.ImageFolder(root = local_dir, transform = test_tfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964bc008",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd3112e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.efficientnet_b5(weights='DEFAULT').to(device)\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.fc = nn.Linear(num_ftrs, n_classes)\n",
    "model.load_state_dict(torch.load(PATH_WEIGHTS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6fdb3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "print(num_ftrs)\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a5251",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f44a3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8622316122055054\n",
      "sunhemp\n",
      "[('sunhemp', 0.8622316122055054), ('sesbania', 0.11614012718200684), ('others', 0.016279706731438637), ('bambooshoots', 0.003470506053417921), ('waterbamboo', 0.0014112989883869886), ('asparagus', 0.0004125163541175425), ('sweetpotato', 1.946224074345082e-05), ('pennisetum', 1.370804511680035e-05), ('taro', 6.687555924145272e-06)]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "IMG_PATH = \"D:/ML_exercise/sunhemp/ffd41947-cac2-4e0b-8e58-e6bfa49019c1.jpg\"\n",
    "Final_label_index = [1, 2, 10, 11, 16, 17, 19, 20, 29, 30]\n",
    "PAR = 0.1\n",
    "img = Image.open(IMG_PATH)\n",
    "x = test_tfm(img).to(device)\n",
    "x = x.unsqueeze(0)\n",
    "output = model(x)\n",
    "#print(output)\n",
    "_, pred = torch.max(output, dim = 1)\n",
    "percentage = nn.functional.softmax(output, dim=1)[0]\n",
    "perc = percentage[int(pred)].item()\n",
    "print(perc)\n",
    "result = species[pred]\n",
    "print(result)\n",
    "\n",
    "# 得到预测结果，并且从大到小排序\n",
    "_, indices = torch.sort(output, descending=True)\n",
    "# 返回每个预测值的百分数\n",
    "print([(species[idx], percentage[idx].item()) for idx in indices[0][:9]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "880098b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([28], device='cuda:0')\n",
      "0.8563043475151062\n",
      "sunhemp\n",
      "[('sunhemp', 0.8563043475151062), ('sesbania', 0.11534174531698227), ('others', 0.021824266761541367), ('bambooshoots', 0.004652494098991156), ('waterbamboo', 0.0014015971682965755), ('asparagus', 0.0004096805932931602), ('sweetpotato', 2.6090710889548063e-05), ('pennisetum', 1.3613811461254954e-05), ('taro', 8.965202141553164e-06)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Final_label_index)):\n",
    "    output[0][Final_label_index[i]] += PAR\n",
    "#print(output)\n",
    "_, pred = torch.max(output, dim = 1)\n",
    "percentage = nn.functional.softmax(output, dim=1)[0]\n",
    "perc = percentage[int(pred)].item()\n",
    "print(perc)\n",
    "result = species[pred]\n",
    "print(result)\n",
    "\n",
    "# 得到预测结果，并且从大到小排序\n",
    "_, indices = torch.sort(output, descending=True)\n",
    "# 返回每个预测值的百分数\n",
    "print([(species[idx], percentage[idx].item()) for idx in indices[0][:9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cabb03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([28], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5102b014",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "List_FileName = list()\n",
    "List_Output = list()\n",
    "for folder in folderNames:\n",
    "    folderPath =  str(local_dir) + '/'  + folder + '/'\n",
    "    for fileName in glob.glob(folderPath + '*'):\n",
    "        print(fileName)\n",
    "        img = Image.open(fileName)\n",
    "        x = test_tfm(img)\n",
    "        x = x.unsqueeze(0)\n",
    "        output = model(x)    \n",
    "        for i in range(len(Final_label_index)):\n",
    "            output[0][Final_label_index[i]] += PAR   \n",
    "        _, pred = torch.max(output, dim = 1)\n",
    "        print(pred)\n",
    "        print(fileName[len(folderPath)::])\n",
    "        print(species[pred])        \n",
    "        List_FileName.append(fileName[len(folderPath)::])\n",
    "        List_Output.append(species[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61c6f378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       filename           label\n",
      "0      09462dbc-ecc4-45d7-8653-9e3a22bbacc2.jpg          longan\n",
      "1      059b89e1-80c1-43a4-be36-cc911dc440f9.jpg      greenhouse\n",
      "2      0ea762fd-124b-4db5-827a-60799a869870.jpg  chinesecabbage\n",
      "3      0e03f42d-70b7-4671-aefe-3e7402ac90a9.jpg     cauliflower\n",
      "4      0f8b5ffa-8609-4e05-afc0-56717bc0c113.jpg    bambooshoots\n",
      "...                                         ...             ...\n",
      "11143  f06bbcf8-f784-4810-92b9-c249c93f3f81.jpg            kale\n",
      "11144  f2efc7a7-48a6-429a-be7f-86884826f223.jpg    bambooshoots\n",
      "11145  fab7c542-6cc0-410c-8b33-8a9e0675029a.jpg      greenhouse\n",
      "11146  fe0231e7-fdf1-4415-b586-e0e815b39ba4.jpg            kale\n",
      "11147  fdc8142c-74ea-4cfe-baf8-bd9c70ed0da7.jpg     sweetpotato\n",
      "\n",
      "[11148 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "output_dict = {\"filename\": List_FileName,\n",
    "                \"label\": List_Output}\n",
    "Out_dataframe = pd.DataFrame(output_dict)\n",
    "print(Out_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3ca204",
   "metadata": {},
   "source": [
    "## Save Csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b6e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FileName =  date.today().strftime(\"%m/%d\").replace('/','') + '.csv'\n",
    "\n",
    "Out_dataframe.to_csv(OUTPUT_CSV_PATH + FileName , index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "82ed002fa2d4956f5c6aec99bcefe0f73a9f79882f3c9e2319b14958a5896ac5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
