{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db67b429",
   "metadata": {},
   "source": [
    "## Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc84052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from datetime import date\n",
    "import glob\n",
    "from PIL import Image\n",
    "from torchvision import  transforms,datasets, models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd60e42",
   "metadata": {},
   "source": [
    "## Private variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42315a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_WEIGHTS = \"D:/ML_exercise/Weights\"\n",
    "folderNames = ['0','1','2','3','4','5','6','7','8','9','a','b','c','d','e','f']\n",
    "OUTPUT_CSV_PATH = \"D:/ML_exercise/PublicTesting_OutputCsv\"\n",
    "#local_dir = \"/work/u2785625/AI_Cup_2022/Datasets\"\n",
    "local_dir = \"D:/ML_exercise/Test_dataset\"\n",
    "n_classes = 33\n",
    "PAR = 0.1\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "species = ['asparagus', 'bambooshoots', 'betel', 'broccoli', 'cauliflower', 'chinesecabbage', 'chinesechives', 'custardapple', 'grape', 'greenhouse', 'greenonion', 'kale', 'lemon', 'lettuce', 'litchi', 'longan', 'loofah', 'mango', 'onion', 'others', 'papaya', 'passionfruit', 'pear', 'pennisetum', 'redbeans', 'roseapple', 'sesbania', 'soybeans', 'sunhemp', 'sweetpotato', 'taro', 'tea', 'waterbamboo']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f588974",
   "metadata": {},
   "source": [
    "## Testing Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f78f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfm = transforms.Compose([ #valid and grading\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((456,456)),\n",
    "    transforms.CenterCrop(456),\n",
    "    transforms.Normalize([.5, 0.5, 0.5], [0.5, 0.5, 0.5]), \n",
    "])\n",
    "\n",
    "#data = datasets.ImageFolder(root = local_dir, transform = test_tfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964bc008",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dd3112e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.efficientnet_b5(weights='DEFAULT')\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.fc = nn.Linear(num_ftrs, n_classes)\n",
    "model.load_state_dict(torch.load(PATH_WEIGHTS, map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a5251",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f44a3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "custardapple\n",
      "[('custardapple', 1.0), ('pear', 2.6621430393447554e-08), ('mango', 5.297584149133172e-09)]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "#IMG_PATH = \"D:/ML_exercise/Test_dataset/0/000bbbfa-15f7-43ba-b99e-0aacada1c782.jpg\"\n",
    "IMG_PATH = \"C:/Users/user/Downloads/318758239_649285323564273_108982210974634080_n.jpg\"\n",
    "#Final_label_index = [1, 2, 10, 11, 16, 17, 19, 20, 29, 30]\n",
    "Final_label_index = [0, 1, 2, 3, 5, 10, 11, 15, 16, 17, 19, 20, 23, 26, 29, 30]\n",
    "img = Image.open(IMG_PATH)\n",
    "x = test_tfm(img).to(device)\n",
    "x = x.unsqueeze(0)\n",
    "output = model(x)\n",
    "#print(output)\n",
    "_, pred = torch.max(output, dim = 1)\n",
    "percentage = nn.functional.softmax(output, dim=1)[0]\n",
    "perc = percentage[int(pred)].item()\n",
    "print(perc)\n",
    "result = species[pred]\n",
    "print(result)\n",
    "\n",
    "# 得到预测结果，并且从大到小排序\n",
    "_, indices = torch.sort(output, descending=True)\n",
    "# 返回每个预测值的百分数\n",
    "print([(species[idx], percentage[idx].item()) for idx in indices[0][:3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "880098b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "custardapple\n",
      "[('custardapple', 1.0), ('pear', 2.6621430393447554e-08), ('mango', 5.8547269254916046e-09)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Final_label_index)):\n",
    "    output[0][Final_label_index[i]] += PAR\n",
    "\n",
    "#print(output)\n",
    "_, pred = torch.max(output, dim = 1)\n",
    "percentage = nn.functional.softmax(output, dim=1)[0]\n",
    "perc = percentage[int(pred)].item()\n",
    "print(perc)\n",
    "result = species[pred]\n",
    "print(result)\n",
    "\n",
    "# 得到预测结果，并且从大到小排序\n",
    "_, indices = torch.sort(output, descending=True)\n",
    "# 返回每个预测值的百分数\n",
    "print([(species[idx], percentage[idx].item()) for idx in indices[0][:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5102b014",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "List_FileName = list()\n",
    "List_Output = list()\n",
    "for folder in folderNames:\n",
    "    #print(folder)\n",
    "    folderPath = str(local_dir)+ '/'  + folder + '/'\n",
    "    for fileName in glob.glob(folderPath + '*'):\n",
    "        #print(fileName)\n",
    "        img = Image.open(fileName)\n",
    "        x = test_tfm(img)\n",
    "        x = x.unsqueeze(0).to(device)\n",
    "        \n",
    "        output = model(x)\n",
    "        for i in range(len(Final_label_index)):\n",
    "            output[0][Final_label_index[i]] += PAR\n",
    "        _, pred = torch.max(output, dim = 1)\n",
    "        #print(pred)\n",
    "        #print(fileName[len(folderPath)::])\n",
    "        #print(species[pred])\n",
    "        List_FileName.append(fileName[len(folderPath)::])\n",
    "        List_Output.append(species[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61c6f378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       filename           label\n",
      "0      0005055c-aaaa-4e19-9a9b-23f8fbbe0976.jpg        soybeans\n",
      "1      0006061f-abda-4e2b-a07f-506ce19a0efc.jpg      greenonion\n",
      "2      00069669-5fc6-46fb-91c1-d9d7abba85ea.jpg     waterbamboo\n",
      "3      000bbbfa-15f7-43ba-b99e-0aacada1c782.jpg  chinesecabbage\n",
      "4      001787cb-d749-4e9b-be38-eca87ba0efa8.jpg            pear\n",
      "...                                         ...             ...\n",
      "11143  ffef051e-044c-4e30-9067-4d840a0252e6.jpg          litchi\n",
      "11144  ffefbeee-d580-4aba-bdc8-eecd9cee4591.jpg         lettuce\n",
      "11145  ffefe03e-842c-44cb-a7c2-4649f42742c8.jpg          longan\n",
      "11146  fff5eae5-791c-4d2b-b501-868f443f90f1.jpg      greenonion\n",
      "11147  fff9637a-544f-4dc4-b64f-ba92ebfe075e.jpg           grape\n",
      "\n",
      "[11148 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "output_dict = {\"filename\": List_FileName,\n",
    "                \"label\": List_Output}\n",
    "Out_dataframe = pd.DataFrame(output_dict)\n",
    "print(Out_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3ca204",
   "metadata": {},
   "source": [
    "## Save Csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02b6e86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/ML_exercise/PublicTesting_OutputCsv1215.csv\n"
     ]
    }
   ],
   "source": [
    "FileName =  date.today().strftime(\"%m/%d\").replace('/','') + '.csv'\n",
    "PAR_VALUE = \"_PAR=\" + str(PAR) + \"_Date:\"\n",
    "print(OUTPUT_CSV_PATH + FileName )\n",
    "Out_dataframe.to_csv(OUTPUT_CSV_PATH + FileName, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "82ed002fa2d4956f5c6aec99bcefe0f73a9f79882f3c9e2319b14958a5896ac5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
